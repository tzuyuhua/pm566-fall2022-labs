---
title: "Lab 09"
date: "`r Sys.Date()`"
output: 
    github_document:
      html_preview: false 
    html_document: default
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# HPC

## Problem 1: Make sure your code is nice

Rewrite the following R functions to make them faster. 

```{r}
fun1 <- function(mat) {
  n <- nrow(mat)
  ans <- double(n) 
  for (i in 1:n) {
    ans[i] <- sum(mat[i, ])
  }
  ans
}

fun1alt <- function(mat) {
  # YOUR CODE HERE
  rowSums(mat)
}

#install.packages('matrixStats')
library(matrixStats)

# Cumulative sum by row
fun2 <- function(mat) {
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) {
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1]
    }
  }
  ans
}

fun2alt <- function(mat) {
  # YOUR CODE HERE
  rowCumsums(mat)
}

# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

# Test for the first
microbenchmark::microbenchmark(
  fun1(dat),
  fun1alt(dat), check = "equivalent"
)

# Test for the second
microbenchmark::microbenchmark(
  fun2(dat),
  fun2alt(dat), check = "equivalent"
)
```

## Problem 2: Make things run faster with parallel computing

The following function allows simulating PI

```{r}
sim_pi <- function(n = 1000, i = NULL) {
  p <- matrix(runif(n*2), ncol = 2)
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
```

In order to get accurate estimates, we can run this function multiple times, with the following code:

```{r}
set.seed(1231)
system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans))
})
```

Rewrite the previous code using parLapply() to make it run faster. 

```{r}
library(parallel)
system.time({
cl <- makePSOCKcluster(2)   
clusterSetRNGStream(cl, 1231) # Equivalent to `set.seed(123)`
  # YOUR CODE HERE
  ans <- unlist(parLapply(cl, 1:4000, sim_pi, n = 10000))
  print(mean(ans))
  # YOUR CODE HERE
})

stopCluster(cl)
```

#SQL

Setup a temporary database by running the following chunk


```{r}
# install.packages(c("RSQLite", "DBI"))

library(RSQLite)
library(DBI)

# Initialize a temporary in memory database
con <- dbConnect(SQLite(), ":memory:")

# Download tables
film <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film.csv")
film_category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film_category.csv")
category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/category.csv")

# Copy data.frames to database
dbWriteTable(con, "film", film)
dbWriteTable(con, "film_category", film_category)
dbWriteTable(con, "category", category)
```

##Question 1

How many many movies is there avaliable in each rating catagory.

```{sql, connection=con}
  SELECT  rating,
    COUNT(*) AS count
  FROM film
  GROUP BY rating
```

## Question 2

What is the average replacement cost and rental rate for each rating category.

```{sql, connection=con}
  SELECT  rating,
    AVG(replacement_cost) AS avg_replacement_cost, 
    AVG(rental_rate) AS avg_rental_rate
  FROM film
  GROUP BY rating
```

## Question 3

Use table film_category together with film to find the how many films there are witth each category ID

```{sql, connection=con}
  SELECT  category_id,
    COUNT(*) AS count
  FROM film AS a INNER JOIN film_category AS b
  ON a.film_id = b.film_id
  GROUP BY category_id
```

## Question 4

Incorporate table category into the answer to the previous question to find the name of the most popular category.

First, we look at which category_id is the most popular.

```{sql, connection=con}
  SELECT  category_id,
    COUNT(category_id) AS count
  FROM film AS a INNER JOIN film_category AS b 
  ON a.film_id = b.film_id
  GROUP BY category_id
  ORDER BY count DESC
```

Check the name of category_id 15.

```{sql, connection=con}
  SELECT  category_id, name
  FROM  category 
  WHERE category_id = 15
```
